{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df117886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\miniconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de96e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soil_type_2_elu(soil_type: int) -> int:\n",
    "    assert 0 < soil_type < 41, \\\n",
    "        \"Soil type out of boundary 1~40.\"\n",
    "    code_dict = [\n",
    "        2702, 2703, 2704, 2705, 2706,\n",
    "        2717, 3501, 3502, 4201, 4703,\n",
    "        4704, 4744, 4758, 5101, 5151,\n",
    "        6101, 6102, 6731, 7101, 7102,\n",
    "        7103, 7201, 7202, 7700, 7701,\n",
    "        7702, 7709, 7710, 7745, 7746,\n",
    "        7755, 7756, 7757, 7790, 8703,\n",
    "        8707, 8708, 8771, 8772, 8776,\n",
    "        ]\n",
    "    return code_dict[soil_type - 1]\n",
    "\n",
    "\n",
    "def get_climatic_zone(elu: int) -> int:\n",
    "    res = elu // 1000\n",
    "    assert 0 < res <= 8, \"Climatic zone code out of boundary 1~8.\"\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_geologic_zone(elu: int) -> int:\n",
    "    res = elu % 1000 // 100\n",
    "    assert 0 < res <= 8, \"Geologic zone code out of boundary 1~8.\"\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_third_digit(elu: int) -> int:\n",
    "    return elu % 100 // 10\n",
    "\n",
    "\n",
    "def get_fourth_digit(elu: int) -> int:\n",
    "    return elu % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60856531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the dataframe and return [X, y] without reshuffling nor rescaling.\n",
    "    X is of shape (n,d+2) and y is of shape (n).\n",
    "    The first column of X contains the ID of each record,\n",
    "    whilst the second column contains the area code of each record.\n",
    "    :param mode whether \"train\" or \"test\"\n",
    "    \"\"\"\n",
    "\n",
    "    # soil types\n",
    "    df.insert(loc=0, column=\"Soil_Type\", value=0)\n",
    "    for i in range(1, 41):\n",
    "        column_name = \"Soil_Type\" + str(i)\n",
    "        df.loc[df[column_name] == 1, \"Soil_Type\"] = i\n",
    "        df.drop(column_name, axis=1, inplace=True)\n",
    "\n",
    "    df[\"elu\"] = [soil_type_2_elu(i) for i in df[\"Soil_Type\"]]\n",
    "    df.drop(\"Soil_Type\", axis=1, inplace=True)\n",
    "\n",
    "    df[\"climatic_zone\"] = [get_climatic_zone(i) for i in df[\"elu\"]]\n",
    "    df[\"geologic_zone\"] = [get_geologic_zone(i) for i in df[\"elu\"]]\n",
    "    df[\"third_digit\"] = [get_third_digit(i) for i in df[\"elu\"]]\n",
    "    df[\"fourth_digit\"] = [get_fourth_digit(i) for i in df[\"elu\"]]\n",
    "    # df.drop(\"elu\", axis=1, inplace=True)\n",
    "\n",
    "    # wilderness area\n",
    "    df.insert(loc=0, column=\"Wilderness_Area\", value=0)\n",
    "    for i in range(1, 5):\n",
    "        column_name = \"Wilderness_Area\" + str(i)\n",
    "        df.loc[df[column_name] == 1, \"Wilderness_Area\"] = i\n",
    "        df.drop(column_name, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fadbf572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./data/train.csv\")\n",
    "df_train = preprocess_df(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db92345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot(df):\n",
    "    df_oneHot = df.copy()\n",
    "    for column in ['Wilderness_Area','climatic_zone','geologic_zone','third_digit','fourth_digit']:\n",
    "        oneHot = pd.get_dummies(df[column], prefix=column)\n",
    "        #print(oneHot)\n",
    "        df_oneHot.drop(column,axis=1,inplace = True)\n",
    "        df_oneHot =df_oneHot.join(oneHot)\n",
    "    return df_oneHot\n",
    "\n",
    "def split_aspect(df):\n",
    "    df_split = df.copy()\n",
    "    df_split['aspect_m'] = df_split['Aspect'] + 180 - 75\n",
    "    df_split.loc[df_split['aspect_m']>360, 'aspect_m'] = df_split.loc[df_split['aspect_m']>360,'aspect_m'] - 360\n",
    "    return df_split\n",
    "\n",
    "def sqrt_col(df,col):\n",
    "    df_sqrt = df.copy()\n",
    "    df_sqrt['sqrt_'+col] = np.sqrt(df[col] + 1)\n",
    "    return df_sqrt\n",
    "\n",
    "def drop_id(df):\n",
    "    df_res = df.drop(\"Id\", axis=1, inplace=False)\n",
    "    return df_res\n",
    "\n",
    "def reduce_id(df):\n",
    "    df_res = df.copy()\n",
    "    df_res['reduce_id'] = df_res['Id'] // 100\n",
    "    df_res = df_res.drop('Id',axis=1)\n",
    "    return df_res\n",
    "\n",
    "def dist(df):\n",
    "    df_res = df.copy()\n",
    "    df_res['Distance'] = np.sqrt(df_res['Horizontal_Distance_To_Hydrology'] ** 2 + df_res['Vertical_Distance_To_Hydrology'] ** 2)\n",
    "    return df_res\n",
    "\n",
    "def rel_h(df,col):\n",
    "    df_res = df.copy()\n",
    "    df_res['relative_'+col] = df_res[col] / df_res['Elevation']\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17bc4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def further_processing(df_train):\n",
    "    df_final = split_aspect(df_train)\n",
    "    df_final = oneHot(df_final)\n",
    "    df_final = sqrt_col(df_final,'Horizontal_Distance_To_Hydrology')\n",
    "    df_final = sqrt_col(df_final,'Horizontal_Distance_To_Roadways')\n",
    "    df_final = sqrt_col(df_final,'Horizontal_Distance_To_Fire_Points')\n",
    "    df_final = dist(df_final)\n",
    "    df_final = rel_h(df_final,'Horizontal_Distance_To_Roadways')\n",
    "    df_final = rel_h(df_final,'Horizontal_Distance_To_Fire_Points')\n",
    "    #df_final = reduce_id(df_final)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9bbc338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(df_train):\n",
    "    X = df_train[df_train.columns.difference(['Cover_Type'])]\n",
    "    y = df_train['Cover_Type']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d63c7648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END classifier__learning_rate_init=0.001, classifier__max_iter=400;, score=0.839 total time=  23.5s\n",
      "[CV 2/5] END classifier__learning_rate_init=0.001, classifier__max_iter=400;, score=0.833 total time=  27.9s\n",
      "[CV 3/5] END classifier__learning_rate_init=0.001, classifier__max_iter=400;, score=0.834 total time=  36.6s\n",
      "[CV 4/5] END classifier__learning_rate_init=0.001, classifier__max_iter=400;, score=0.824 total time=  32.9s\n",
      "[CV 5/5] END classifier__learning_rate_init=0.001, classifier__max_iter=400;, score=0.837 total time=  28.7s\n",
      "0.8335317460317461\n"
     ]
    }
   ],
   "source": [
    "df_final = further_processing(df_train)\n",
    "X,y = get_X_y(df_final)\n",
    "pipeline = Pipeline([('variance',VarianceThreshold(threshold=(.8 * (1 - .8)))),\n",
    "                     ('scaler', StandardScaler()),\n",
    "                     ('classifier', MLPClassifier(hidden_layer_sizes = (64,32,16,) ))])\n",
    "\n",
    "param_grid = {\n",
    "#     'classifier__max_bin': [255],\n",
    "    'classifier__learning_rate_init': [0.0001,0.001,0.01],\n",
    "    'classifier__max_iter': [400],\n",
    "#     'classifier__n_estimators': [100],\n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipeline, param_grid, scoring='accuracy', verbose=3)\n",
    "\n",
    "model.fit(X, y)\n",
    "print(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1412f53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.4,\n",
       " 'classifier__max_bin': 255,\n",
       " 'classifier__n_estimators': 100,\n",
       " 'classifier__num_leaves': 63}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f7f27a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (25) does not match length of index (51)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14184\\2670824536.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m feature_imp = pd.Series(model.best_estimator_['classifier'].feature_importances_, \n\u001b[0m\u001b[0;32m      2\u001b[0m                         index=X.columns).sort_values(ascending=False)\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_imp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_imp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature Importance Score'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\miniconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    459\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m                 \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[1;31m# create/copy the manager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\miniconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \"\"\"\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    562\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (25) does not match length of index (51)"
     ]
    }
   ],
   "source": [
    "feature_imp = pd.Series(model.best_estimator_['classifier'].feature_importances_, \n",
    "                        index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "print(sns.barplot(x=feature_imp, y=feature_imp.index))\n",
    "plt.xlabel('Feature Importance Score', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title(\"Visualizing Important Features\", fontsize=15, pad=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7978ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"./data/test-full.csv\")\n",
    "df_test = preprocess_df(df_test)\n",
    "ids = df_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5db9bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_test = further_processing(df_test)\n",
    "best_model = model.best_estimator_\n",
    "y_test = best_model.predict(df_final_test[X.columns])\n",
    "df_result = pd.DataFrame(list(zip(ids, y_test)), columns=['Id', 'Cover_Type'])\n",
    "df_result.to_csv(\"./data/lgbm_feature_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c343c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
